Feature Engineering:
1. Remove Features related to home form and away form 
2. Take only one of variables with high spearman correlation with each other (> 0.7)
3. Remove variables that contributes little to target variable (identify using boxplots)
4. Remove variables with low Boruta score (< 0.5)
5. Standardization

Features Used:
HASLxM, HAFLxM, HAGCLxM, HWPLxM, AASLxM, AAGCLxM, AWPLxM, HOvr, AOvr, B365H, B365D, B365A


Model Accuracies:
Accuracy on Test Set (Random Forest):
- 0.5578
- {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'n_estimators': 300}

Accuracy on Test Set (Logistic Regression):
- 0.545
- {'C': 0.08858667904100823, 'penalty': 'l1', 'solver': 'liblinear'}

Accuracy on Test Set (Support Vector):
- 0.541
- {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}

Accuracy on Test Set (XGBoost):
- 0.559
- {'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 180}
